# RetrieveAndGenerate Lambda Function - Documentation

## Table of Contents
1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Configuration](#configuration)
4. [Security Audit](#security-audit)
5. [Improvement Roadmap](#improvement-roadmap)
6. [Implementation Guide](#implementation-guide)
7. [Testing & Monitoring](#testing--monitoring)
8. [Deployment Checklist](#deployment-checklist)

---

## Overview

### Purpose
AWS Lambda function that orchestrates a RAG (Retrieval-Augmented Generation) workflow using Amazon Bedrock Knowledge Bases. Acts as a secure backend for the Duoc UC chatbot, providing AI-powered responses with source citations.

### Security Status
‚úÖ **Phase 1: Security Hardening - COMPLETE**
- ‚úÖ Prompt injection detection implemented
- ‚úÖ CORS origin validation implemented
- ‚úÖ Input sanitization implemented
- ‚úÖ Output validation implemented
- ‚úÖ Timeout handling implemented
- ‚úÖ Request ID tracking implemented

### Current Status
- ‚úÖ Basic RAG implementation functional
- ‚úÖ Single-query processing with citations
- ‚úÖ Conversational context implemented (Phase 0 complete - using sessionStorage)
- ‚úÖ Input validation (query length, history format)
- ‚úÖ Type hints and structured logging
- ‚úÖ Specific exception handling (boto3 errors)
- ‚úÖ Response structure validation
- ‚úÖ X-Ray tracing implemented
- ‚úÖ Prompt injection detection (Phase 1 complete)
- ‚úÖ CORS origin validation (Phase 1 complete)
- ‚úÖ Input sanitization (Phase 1 complete)
- ‚úÖ Output validation (Phase 1 complete)
- ‚úÖ Timeout handling (Phase 1 complete)
- ‚úÖ Request ID tracking (Phase 1 complete)
- ‚úÖ Citation validation (Phase 3 partial - score filtering implemented)
- ‚úÖ LLM Guard integration (Phase 1 enhanced - optional)
- ‚úÖ Query optimization (Phase 2 complete - expansion, hybrid search, decomposition)
- üîÑ Advanced response quality validation (Phase 3 partial - factuality checking pending)

---

## Architecture

### Current Flow
```
User Query ‚Üí API Gateway ‚Üí Lambda ‚Üí Bedrock Knowledge Base ‚Üí OpenSearch
                                                                    ‚Üì
User Response ‚Üê Lambda ‚Üê LLM Generation ‚Üê Retrieved Context ‚Üê Search Results
```

**Note:** Conversational context is managed by the frontend using sessionStorage. Each request includes the conversation history.

### Proposed Flow (With Context)
```
Frontend (maintains history in sessionStorage/memory)
    ‚Üì
User Query + Conversation History ‚Üí API Gateway ‚Üí Lambda
    ‚Üì
Context-Enhanced Query ‚Üí Bedrock Knowledge Base ‚Üí OpenSearch
    ‚Üì
Retrieved Context + Conversation History ‚Üí LLM Generation
    ‚Üì
Response + Citations ‚Üí Lambda ‚Üí Frontend (updates sessionStorage history)
```

### Components

| Component | Current Implementation | Purpose |
|-----------|----------------------|---------|
| **Input** | `query` (string) + `history` (array) | User question with conversation history |
| **Processing** | Bedrock `retrieve_and_generate()` | RAG pipeline with contextual prompts |
| **Output** | `answer` (string) + `sources` (array) | AI response with citations |
| **Context** | ‚úÖ Frontend-managed (sessionStorage) | Conversational memory (last 10 messages) |
| **Storage** | ‚úÖ Frontend (sessionStorage) | History management (no database needed) |
| **Security** | ‚úÖ Complete (Phase 1 complete) | Input validation, prompt injection detection, CORS, timeout handling |

### Response Format
```json
{
  "answer": "Generated answer text with context",
  "sources": [
    {
      "document": "s3://bucket/path/to/doc.pdf",
      "excerpt": "Relevant text excerpt from document",
      "score": 0.95
    }
  ]
}
```

---

## Configuration

### Environment Variables

#### Required
| Variable | Example | Description |
|----------|---------|-------------|
| `KNOWLEDGE_BASE_ID` | `abc123xyz` | Bedrock Knowledge Base ID |
| `MODEL_ARN` | `cohere.command-r-v1:0` | Bedrock LLM model ARN |
| `ALLOWED_ORIGIN` | `https://duoc.cl` | CORS allowed origin |

#### Optional
| Variable | Default | Range | Description |
|----------|---------|-------|-------------|
| `AWS_REGION` | `us-east-1` | - | AWS region |
| `TEMPERATURE` | `0.2` | 0.0-1.0 | LLM creativity (lower = more deterministic) |
| `MAX_TOKENS` | `1024` | 1-4096 | Maximum response length |
| `MAX_QUERY_LENGTH` | `5000` | - | Query character limit |
| `MAX_CONTEXT_MESSAGES` | `10` | - | Conversation history limit (managed in frontend sessionStorage) |
| `MIN_TIMEOUT_SECONDS` | `5.0` | - | Minimum seconds remaining before Lambda timeout |
| `MIN_CITATION_SCORE` | `0.7` | 0.0-1.0 | Minimum relevance score for citations (Phase 3) |
| `MAX_CITATIONS` | `5` | 1-20 | Maximum number of citations to return (Phase 3) |
| `LLM_GUARD_ENABLED` | `false` | true/false | Enable LLM Guard for enhanced security |
| `LLM_GUARD_THRESHOLD` | `0.5` | 0.0-1.0 | Risk threshold for LLM Guard detection |
| `QUERY_OPTIMIZATION_ENABLED` | `true` | true/false | Enable query optimization (Phase 2) |
| `QUERY_EXPANSION_ENABLED` | `true` | true/false | Enable query expansion with synonyms |
| `HYBRID_SEARCH_ENABLED` | `true` | true/false | Enable hybrid search (semantic + keyword) |
| `QUERY_DECOMPOSITION_ENABLED` | `true` | true/false | Enable complex query decomposition |
| `MAX_QUERY_EXPANSIONS` | `3` | 1-10 | Maximum number of synonyms to add per query |

### IAM Permissions Required
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "bedrock:RetrieveAndGenerate",
        "bedrock:InvokeModel"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "arn:aws:logs:*:*:*"
    },
    {
      "Effect": "Allow",
      "Action": "xray:PutTraceSegments",
      "Resource": "*"
    }
  ]
}
```

---

## Security Audit

### üî¥ Critical Issues

| # | Issue | Impact | Priority | Status |
|---|-------|--------|----------|--------|
| 1 | **No input validation** | Resource exhaustion, injection attacks | Critical | ‚úÖ Implementado |
| 2 | **Weak CORS validation** | Security bypass potential | Critical | ‚úÖ Implementado |
| 3 | **No rate limiting** | DoS vulnerability | Critical | üìã Planificado |
| 4 | **Generic error handling** | Information leakage | High | ‚úÖ Implementado |
| 5 | **No authentication** | Public access (by design for duoc.cl) | N/A* | ‚úÖ Por dise√±o |

*Note: Public access is intentional for student chatbot. Mitigate with API Gateway throttling and WAF rules.*

### üü° Medium Issues

| # | Issue | Impact | Priority | Status |
|---|-------|--------|----------|--------|
| 6 | **No request validation** | Malformed requests cause errors | Medium | ‚úÖ Implementado |
| 7 | **Hardcoded config values** | Difficult to tune without redeployment | Medium | ‚úÖ Implementado |
| 8 | **No timeout handling** | Hanging requests | Medium | ‚úÖ Implementado |

### üü¢ Low Priority Issues

| # | Issue | Impact | Priority | Status |
|---|-------|--------|----------|--------|
| 9 | **Missing type hints** | Reduced maintainability | Low | ‚úÖ Implementado |
| 10 | **No unit tests** | Difficult to validate changes | Low | üîÑ Pendiente |
| 11 | **No structured logging** | Difficult to debug | Low | ‚úÖ Implementado |

---

## Prompt Injection Security

### Overview

**Prompt Injection** es una vulnerabilidad cr√≠tica en aplicaciones LLM donde un atacante manipula el input del usuario para inyectar instrucciones maliciosas que el modelo ejecuta, potencialmente:
- Revelando instrucciones del sistema
- Bypasseando restricciones de seguridad
- Accediendo a informaci√≥n confidencial
- Modificando el comportamiento del sistema

### Vulnerabilidades de Prompt Injection Identificadas

| Vulnerabilidad | Estado | Mitigaci√≥n |
|----------------|--------|------------|
| **Input validation** | ‚úÖ Implementado | Validaci√≥n de longitud, sanitizaci√≥n y detecci√≥n de injection implementadas |
| **Detecci√≥n de patrones peligrosos** | ‚úÖ Implementado | Filtro de prompt injection implementado |
| **Sanitizaci√≥n de inputs** | ‚úÖ Implementado | Normalizaci√≥n y filtrado de caracteres peligrosos implementado |
| **Validaci√≥n de CORS origin** | ‚úÖ Implementado | Validaci√≥n estricta de origen implementada |
| **Timeout handling** | ‚úÖ Implementado | Verificaci√≥n de tiempo restante implementada |
| **Output validation** | ‚úÖ Implementado | Validaci√≥n de patrones sospechosos en respuestas implementada |
| **Request ID tracking** | ‚úÖ Implementado | Tracking de solicitudes para correlaci√≥n implementado |

### Medidas de Protecci√≥n Implementadas

- ‚úÖ **Validaci√≥n de longitud** de queries (MAX_QUERY_LENGTH: 5000 caracteres)
- ‚úÖ **Validaci√≥n de formato** de historial de conversaci√≥n
- ‚úÖ **Validaci√≥n de estructura** de respuestas de Bedrock
- ‚úÖ **Manejo espec√≠fico de excepciones** con c√≥digos de error apropiados
- ‚úÖ **Logging estructurado** con contexto adicional
- ‚úÖ **Type hints** en todas las funciones
- ‚úÖ **Detecci√≥n de prompt injection** con filtro de patrones peligrosos
- ‚úÖ **Sanitizaci√≥n de inputs** con normalizaci√≥n y filtrado
- ‚úÖ **Validaci√≥n de outputs** para detectar fugas de informaci√≥n
- ‚úÖ **Timeout handling** con verificaci√≥n de tiempo restante
- ‚úÖ **Request ID tracking** en todas las respuestas y logs

### Medidas de Protecci√≥n Planificadas

- ‚úÖ **Detecci√≥n de patrones peligrosos** - `PromptInjectionFilter` implementado
- ‚úÖ **Sanitizaci√≥n de inputs** - Normalizaci√≥n y filtrado implementado
- ‚úÖ **Validaci√≥n de CORS origin** - Validaci√≥n estricta implementada
- ‚úÖ **Timeout handling** - Verificaci√≥n de tiempo restante implementada
- ‚úÖ **Request ID tracking** - Request ID incluido en respuestas y logs
- ‚úÖ **Validaci√≥n de outputs** - Detecci√≥n de fugas implementada

### Patrones Peligrosos a Detectar

Los siguientes patrones deben ser detectados y bloqueados:

```python
DANGEROUS_PATTERNS = [
    r'ignore\s+(all\s+)?previous\s+instructions?',
    r'you\s+are\s+now\s+(in\s+)?developer\s+mode',
    r'system\s+override',
    r'reveal\s+prompt',
    r'forget\s+(all\s+)?previous',
    r'new\s+instructions?',
    r'override\s+system',
    r'ignore\s+all\s+rules',
    r'you\s+must\s+now',
    r'disregard\s+previous',
]
```

### Mejores Pr√°cticas de Seguridad

#### 1. Input Validation y Sanitizaci√≥n

- **Detecci√≥n de patrones peligrosos** usando expresiones regulares
- **Detecci√≥n fuzzy** para typoglycemia (palabras con letras mezcladas)
- **Normalizaci√≥n de espacios** en blanco y caracteres invisibles
- **Remoci√≥n de repetici√≥n** de caracteres (aaaa -> a)
- **Filtrado de caracteres invisibles** Unicode

#### 2. Estructuraci√≥n de Prompts

- **Separaci√≥n clara** entre instrucciones del sistema y datos del usuario
- **Instrucciones expl√≠citas** para tratar input del usuario como DATA, no COMMANDOS
- **Reglas de seguridad** integradas en el system prompt
- **Rechazo autom√°tico** de solicitudes que intentan ignorar reglas

#### 3. Validaci√≥n de Output

- **Detecci√≥n de fugas** de system prompt en respuestas
- **Detecci√≥n de exposici√≥n** de API keys o informaci√≥n sensible
- **Validaci√≥n de patrones sospechosos** en respuestas
- **L√≠mite de longitud** de respuestas

#### 4. Validaci√≥n de CORS

- **Validaci√≥n estricta** del header `Origin` del request
- **Comparaci√≥n exacta** con `ALLOWED_ORIGIN` configurado
- **Rechazo de requests** con origen no autorizado
- **No usar '*' en producci√≥n** (solo para desarrollo)

#### 5. Timeout Handling

- **Verificaci√≥n de tiempo restante** antes de procesar requests
- **Configuraci√≥n de timeout** en cliente boto3
- **Manejo de timeouts** de Bedrock API
- **Respuesta apropiada** cuando se detecta timeout inminente

#### 6. Request ID Tracking

- **Extracci√≥n de request ID** del evento Lambda
- **Inclusi√≥n en logs** para correlaci√≥n
- **Inclusi√≥n en respuestas** para debugging del cliente
- **Tracking de intentos** de injection por request ID

### Implementaci√≥n Recomendada

Ver documentaci√≥n detallada en: [Prompt Injection Security Guide](../docs/prompt-injection-security.md)

La documentaci√≥n incluye:
- C√≥digo completo de `PromptInjectionFilter`
- C√≥digo completo de `OutputValidator`
- Funciones de validaci√≥n de CORS
- Funciones de timeout handling
- Integraci√≥n con LLM Guard (librer√≠a especializada)
- Checklist completo de seguridad
- Referencias a OWASP y mejores pr√°cticas

### Integraci√≥n con LLM Guard (Opcional)

‚úÖ **IMPLEMENTADO** - Para una protecci√≥n m√°s robusta, se ha integrado [LLM Guard](https://github.com/protectai/llm-guard):

**Configuraci√≥n:**
- Agregar `llm-guard>=2.0.0` a `requirements.txt`
- Configurar variables de entorno:
  - `LLM_GUARD_ENABLED=true` (default: false)
  - `LLM_GUARD_THRESHOLD=0.5` (default: 0.5)

**Funcionamiento:**
- LLM Guard se usa como primera capa de detecci√≥n si est√° habilitado
- Si LLM Guard no est√° disponible o falla, se usa el filtro manual como fallback
- Proporciona risk_score para mejor logging y auditor√≠a
- Sanitiza autom√°ticamente el input cuando es v√°lido

**C√≥digo implementado:**
```python
from llm_guard.input_scanners import PromptInjection
from llm_guard.input_scanners.prompt_injection import MatchType

# Inicializaci√≥n autom√°tica si LLM_GUARD_ENABLED=true
llm_guard_scanner = PromptInjection(
    threshold=LLM_GUARD_THRESHOLD,
    match_type=MatchType.FULL
)

# Uso en detecci√≥n de prompt injection
sanitized_query, is_valid, risk_score = llm_guard_scanner.scan(query)
```

### Referencias

- [Prompt Injection Security Guide](../docs/prompt-injection-security.md) - Documentaci√≥n completa
- [LLM Guard Documentation](https://github.com/protectai/llm-guard) - Librer√≠a especializada
- [OWASP LLM Prompt Injection Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/LLM_Prompt_Injection_Prevention_Cheat_Sheet.html) - Mejores pr√°cticas OWASP
- [Aporia Guardrails](https://gr-docs.aporia.com/) - Plataforma de guardrails para LLM

---

## Improvement Roadmap

### üö® Phase 0: Critical - Conversational Context (1-2 days)

**Problem:** Chatbot cannot remember previous messages, making follow-up questions impossible.

**Example:**
- ‚ùå Current: "When do classes start?" ‚Üí "December 20th" ‚Üí "And how much does it cost?" ‚Üí ‚ö†Ô∏è No context!
- ‚úÖ With context: "When do classes start?" ‚Üí "December 20th" ‚Üí "And how much does it cost?" ‚Üí "Classes starting December 20th cost..."

**Solution:** Frontend-managed conversation history (no database needed!)

#### Implementation Strategy

```
Frontend (sessionStorage/memory) ‚Üí Lambda ‚Üí Bedrock (with context)
```

**Key Benefits:**
- ‚úÖ No DynamoDB costs
- ‚úÖ No additional IAM permissions
- ‚úÖ Lower latency (no database queries)
- ‚úÖ History persists during session (better UX)
- ‚úÖ Optional "Clear History" button for user control

**Technical Approach:**
1. Frontend maintains last 10 messages (5 user + 5 assistant) in `sessionStorage`
2. Each request includes full conversation history
3. Lambda builds contextual query using history
4. LLM intelligently uses context only when relevant

**Behavior with Different Question Types:**

| Scenario | Example | LLM Behavior |
|----------|---------|--------------|
| **Follow-up question** | "When do classes start?" ‚Üí "December 20th" ‚Üí "And how much?" | Uses context: "Classes starting December 20th cost $500" |
| **Independent question** | "When do classes start?" ‚Üí "December 20th" ‚Üí "What careers at San Joaqu√≠n?" | Ignores context: "At San Joaqu√≠n: Medicine, Engineering" |

**Implementation Time:** 1-2 days

---

### üî• Phase 1: Security Hardening (2-3 days)

**Priorities:**
1. ‚úÖ Input validation (query length) - **IMPLEMENTADO**
2. ‚úÖ Specific exception handling (boto3 errors) - **IMPLEMENTADO**
3. ‚úÖ CORS origin validation - **IMPLEMENTADO**
4. ‚úÖ Response structure validation - **IMPLEMENTADO**
5. ‚úÖ Request ID tracking - **IMPLEMENTADO**
6. ‚úÖ Prompt injection detection - **IMPLEMENTADO**
7. ‚úÖ Input sanitization - **IMPLEMENTADO**
8. ‚úÖ Output validation - **IMPLEMENTADO**
9. ‚úÖ Timeout handling - **IMPLEMENTADO**

**Estado actual:**
- ‚úÖ Validaci√≥n de longitud de query implementada
- ‚úÖ Manejo espec√≠fico de excepciones de boto3 implementado
- ‚úÖ Validaci√≥n de estructura de respuesta implementada
- ‚úÖ Validaci√≥n de CORS origin implementada
- ‚úÖ Detecci√≥n de prompt injection implementada
- ‚úÖ Sanitizaci√≥n de inputs implementada
- ‚úÖ Validaci√≥n de outputs implementada
- ‚úÖ Timeout handling implementado
- ‚úÖ Request ID tracking implementado

**Referencias:** Ver secci√≥n [Prompt Injection Security](#prompt-injection-security) arriba para detalles completos y c√≥digo de implementaci√≥n.

---

### ‚ö° Phase 2: Query Optimization (1 week)

**Goals:**
- ‚úÖ Query expansion with synonyms - **IMPLEMENTADO**
- ‚úÖ Hybrid search (semantic + keyword) - **IMPLEMENTADO**
- ‚úÖ Complex query decomposition - **IMPLEMENTADO**
- ‚úÖ Context-aware query enhancement - **IMPLEMENTADO**

**Estado actual:**
- ‚úÖ Expansi√≥n de queries con sin√≥nimos implementada
- ‚úÖ B√∫squeda h√≠brida (sem√°ntica + keywords) implementada
- ‚úÖ Descomposici√≥n de queries complejas implementada
- ‚úÖ Mejora de queries con contexto de conversaci√≥n implementada
- ‚úÖ Variables de entorno configurables para habilitar/deshabilitar optimizaciones

---

### üéØ Phase 3: Response Quality (1 week)

**Goals:**
- ‚úÖ Citation validation (verify sources support answer) - **IMPLEMENTADO**
- ‚úÖ Citation relevance scoring - **IMPLEMENTADO**
- üîÑ Factuality checking (hallucination detection) - **PENDIENTE**
- üîÑ Contradiction detection - **PENDIENTE**

**Estado actual:**
- ‚úÖ Filtrado de citas por score m√≠nimo (MIN_CITATION_SCORE: 0.7)
- ‚úÖ Ordenamiento de citas por relevancia (score descendente)
- ‚úÖ L√≠mite de cantidad de citas (MAX_CITATIONS: 5)
- ‚úÖ Validaci√≥n de que haya citas v√°lidas
- ‚úÖ Logging de citas filtradas para auditor√≠a

---

### üöÄ Phase 4: Advanced Retrieval (1-2 weeks)

**Goals:**
- Cross-encoder re-ranking
- Metadata filtering
- Diversity sampling
- Context window optimization

---

## Implementation Guide

### Phase 0: Conversational Context

#### Step 1: Frontend - ChatHistory Class

```javascript
class ChatHistory {
    constructor() {
        this.messages = [];
        this.MAX_MESSAGES = 10;
        this.STORAGE_KEY = 'duocChatHistory';
        this.loadFromStorage();
    }
    
    addMessage(role, content) {
        this.messages.push({ role, content });
        if (this.messages.length > this.MAX_MESSAGES) {
            this.messages = this.messages.slice(-this.MAX_MESSAGES);
        }
        this.saveToStorage();
    }
    
    getHistory() {
        return this.messages;
    }
    
    clear() {
        this.messages = [];
        sessionStorage.removeItem(this.STORAGE_KEY);
    }
    
    saveToStorage() {
        try {
            sessionStorage.setItem(
                this.STORAGE_KEY, 
                JSON.stringify(this.messages)
            );
        } catch (e) {
            console.warn('Could not save history:', e);
        }
    }
    
    loadFromStorage() {
        try {
            const stored = sessionStorage.getItem(this.STORAGE_KEY);
            if (stored) {
                this.messages = JSON.parse(stored);
            }
        } catch (e) {
            console.warn('Could not load history:', e);
            this.messages = [];
        }
    }
}
```

#### Step 2: Frontend - Integration

**Modify `chatbot.js`:**

```javascript
// 1. Add property to chatbot object
const chatbot = {
    history: null,  // Add this line
    
    // 2. Initialize in init()
    init() {
        this.history = new ChatHistory();
        // ... rest of init code
    },
    
    // 3. Modify sendMessage()
    async sendMessage(message) {
        // BEFORE adding to UI
        this.history.addMessage('user', message);
        
        // Add to UI
        this.addMessage(message, 'user');
        
        // Modify fetch request
        const response = await fetch(API_ENDPOINT, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
                query: message,
                history: this.history.getHistory()  // Add history
            })
        });
        
        const data = await response.json();
        
        // AFTER receiving response
        this.history.addMessage('assistant', data.answer);
        
        // Add to UI
        this.addMessage(data.answer, 'bot');
    }
};
```

#### Step 3: Lambda - Context Builder

```python
def build_context_prompt(query: str, history: List[Dict]) -> str:
    """
    Builds contextual query from conversation history.
    
    Instructs LLM to use context only when relevant.
    For independent questions, LLM ignores previous context.
    """
    if not history:
        return query
    
    context_parts = [
        "Previous conversation:",
        "IMPORTANT: Use this context ONLY if relevant to the current question.",
        "If the current question is about a different topic, ignore previous context."
    ]
    
    # Add conversation history
    for msg in history[-10:]:  # Last 10 messages only
        role = msg.get('role', 'user').capitalize()
        content = msg.get('content', '').strip()
        if content:
            context_parts.append(f"{role}: {content}")
    
    # Add current question
    context_parts.extend([
        f"\nCurrent question: {query}",
        "\nInstructions: Answer the current question. Use previous context only if directly relevant."
    ])
    
    return "\n".join(context_parts)
```

#### Step 4: Lambda - Handler Update

```python
import json
import os
import boto3
from typing import Dict, List, Any

# Environment variables
KNOWLEDGE_BASE_ID = os.environ['KNOWLEDGE_BASE_ID']
MODEL_ARN = os.environ['MODEL_ARN']
TEMPERATURE = float(os.environ.get('TEMPERATURE', '0.2'))
MAX_TOKENS = int(os.environ.get('MAX_TOKENS', '1024'))
MAX_QUERY_LENGTH = int(os.environ.get('MAX_QUERY_LENGTH', '5000'))

# Initialize Bedrock client
bedrock_agent_runtime = boto3.client('bedrock-agent-runtime')

def handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    Lambda handler with conversational context support.
    """
    try:
        # Parse request
        body = json.loads(event.get('body', '{}'))
        query = body.get('query', '').strip()
        history = body.get('history', [])
        
        # Validate query
        if not query:
            return create_response(400, {'error': 'Query is required'})
        
        if len(query) > MAX_QUERY_LENGTH:
            return create_response(400, {'error': f'Query exceeds maximum length of {MAX_QUERY_LENGTH}'})
        
        # Validate history format
        if history and not isinstance(history, list):
            history = []
        
        # Build contextual query
        contextual_query = build_context_prompt(query, history)
        
        # Call Bedrock with context
        response = bedrock_agent_runtime.retrieve_and_generate(
            input={'text': contextual_query},
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': KNOWLEDGE_BASE_ID,
                    'modelArn': MODEL_ARN,
                    'generationConfiguration': {
                        'inferenceConfig': {
                            'textInferenceConfig': {
                                'temperature': TEMPERATURE,
                                'maxTokens': MAX_TOKENS,
                            }
                        }
                    }
                }
            }
        )
        
        # Validate response structure
        if 'output' not in response or 'text' not in response['output']:
            raise ValueError("Invalid Bedrock response structure")
        
        # Extract answer and sources
        answer = response['output']['text']
        citations = response.get('citations', [])
        sources = format_sources(citations)
        
        # Return response
        return create_response(200, {
            'answer': answer,
            'sources': sources
        })
        
    except json.JSONDecodeError:
        return create_response(400, {'error': 'Invalid JSON in request body'})
    
    except Exception as e:
        print(f"Error: {str(e)}")
        return create_response(500, {'error': 'Internal server error'})

def format_sources(citations: List[Dict]) -> List[Dict]:
    """Format citation sources for response."""
    sources = []
    for citation in citations:
        for reference in citation.get('retrievedReferences', []):
            sources.append({
                'document': reference.get('location', {}).get('s3Location', {}).get('uri', ''),
                'excerpt': reference.get('content', {}).get('text', ''),
                'score': reference.get('metadata', {}).get('score', 0.0)
            })
    return sources

def create_response(status_code: int, body: Dict) -> Dict:
    """Create HTTP response with CORS headers."""
    return {
        'statusCode': status_code,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': os.environ.get('ALLOWED_ORIGIN', '*'),
            'Access-Control-Allow-Methods': 'POST, OPTIONS',
            'Access-Control-Allow-Headers': 'Content-Type'
        },
        'body': json.dumps(body)
    }
```

#### Step 5: Testing

**Test Cases:**

1. **Follow-up question:**
   ```
   User: "What are the enrollment requirements?"
   Bot: "Requirements are: ..."
   User: "And how much does it cost?"
   Expected: Bot uses context to understand "it" refers to enrollment
   ```

2. **Independent question:**
   ```
   User: "When do classes start?"
   Bot: "December 20th"
   User: "What careers at San Joaqu√≠n campus?"
   Expected: Bot responds only about careers, ignores class dates
   ```

3. **Context window limit:**
   ```
   Send 15 messages
   Expected: Only last 10 messages maintained in frontend
   ```

4. **Browser close:**
   ```
   Close browser tab
   Reopen chatbot
   Expected: History is cleared (sessionStorage)
   ```

---

## Testing & Monitoring

### Unit Tests

```python
# test_handler.py
import pytest
from lambda_function import build_context_prompt, handler

def test_build_context_prompt_no_history():
    query = "What is Duoc UC?"
    history = []
    result = build_context_prompt(query, history)
    assert result == query

def test_build_context_prompt_with_history():
    query = "And how much does it cost?"
    history = [
        {"role": "user", "content": "What are enrollment requirements?"},
        {"role": "assistant", "content": "Requirements are..."}
    ]
    result = build_context_prompt(query, history)
    assert "Previous conversation:" in result
    assert "enrollment requirements" in result
    assert query in result

def test_handler_missing_query():
    event = {"body": json.dumps({})}
    response = handler(event, None)
    assert response['statusCode'] == 400
    assert 'error' in json.loads(response['body'])
```

### Integration Tests

```bash
# Test with curl
curl -X POST https://your-api.execute-api.us-east-1.amazonaws.com/prod/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the enrollment requirements?",
    "history": []
  }'

# Test with history
curl -X POST https://your-api.execute-api.us-east-1.amazonaws.com/prod/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "And how much does it cost?",
    "history": [
      {"role": "user", "content": "What are enrollment requirements?"},
      {"role": "assistant", "content": "Requirements are..."}
    ]
  }'
```

### CloudWatch Metrics

**Recommended Alarms:**

| Metric | Threshold | Action |
|--------|-----------|--------|
| Error Rate | > 5% | SNS notification |
| P50 Latency | > 5 seconds | SNS notification |
| Throttle Count | > 0 | SNS notification |

**Custom Metrics to Track:**
- Requests with/without history
- Average history size
- Context window truncations
- Query length distribution

---

## Deployment Checklist

### Pre-Deployment

- [ ] **Environment Variables Configured**
  - [ ] `KNOWLEDGE_BASE_ID` set
  - [ ] `MODEL_ARN` set
  - [ ] `ALLOWED_ORIGIN` set to production domain
  - [ ] `TEMPERATURE` tuned (default 0.2)
  - [ ] `MAX_TOKENS` configured (default 1024)

- [ ] **IAM Permissions**
  - [ ] Bedrock access granted
  - [ ] CloudWatch Logs access granted
  - [ ] X-Ray tracing enabled

- [ ] **API Gateway**
  - [ ] POST endpoint configured
  - [ ] CORS headers enabled
  - [ ] Throttling configured (e.g., 100 req/second)
  - [ ] Request size limit validated (10MB max)

### Code Quality

- [ ] **Lambda Handler**
  - [ ] Context management implemented
  - [ ] Input validation added
  - [ ] Error handling improved
  - [ ] Type hints added
  - [ ] Logging configured

- [ ] **Frontend**
  - [ ] `ChatHistory` class implemented
  - [ ] sessionStorage integration working
  - [ ] History sent with each request
  - [ ] 10-message limit enforced

### Testing

- [ ] **Unit Tests**
  - [ ] `build_context_prompt` tested
  - [ ] `ChatHistory` class tested
  - [ ] Error scenarios covered

- [ ] **Integration Tests**
  - [ ] Single query tested
  - [ ] Multi-turn conversation tested
  - [ ] Context window limit tested
  - [ ] History format validated

- [ ] **Load Testing**
  - [ ] Concurrent requests tested
  - [ ] Large payloads tested
  - [ ] Rate limiting validated

### Monitoring

- [ ] **CloudWatch**
  - [ ] Error rate alarm configured
  - [ ] Latency alarm configured
  - [ ] Custom metrics dashboard created

- [ ] **X-Ray**
  - [ ] Tracing enabled
  - [ ] Service map visible

### Documentation

- [ ] API documentation updated
- [ ] Frontend integration guide created
- [ ] Troubleshooting guide written
- [ ] Runbook for common issues prepared

---

## Cost Optimization

### No Database Costs üéâ

**Frontend-managed history eliminates:**
- ‚ùå DynamoDB costs (read/write operations)
- ‚ùå Additional IAM permissions
- ‚ùå Database query latency

**Cost Breakdown:**
- Lambda invocations: ~$0.20 per 1M requests
- API Gateway: ~$3.50 per 1M requests
- Bedrock API: Variable (based on model and tokens)
- Additional payload: ~1-2 KB per request (negligible)

**Optimization Tips:**
- Keep history at 10 messages (balance context vs payload size)
- Monitor API Gateway payload size (10MB limit)
- Use efficient JSON serialization
- Consider compression for very long conversations

---

## Troubleshooting

### Common Issues

**1. "No context being used in responses"**
- ‚úÖ Check: Frontend sending `history` array?
- ‚úÖ Check: Lambda receiving history in event body?
- ‚úÖ Check: `build_context_prompt` being called?
- ‚úÖ Check: CloudWatch logs for contextual query

**2. "History not persisting"**
- ‚úÖ Check: `sessionStorage` supported in browser?
- ‚úÖ Check: `ChatHistory.saveToStorage()` being called?
- ‚úÖ Check: Browser console for storage errors
- ‚úÖ Check: Privacy mode disabled (blocks sessionStorage)?
- ‚ö†Ô∏è **Note:** sessionStorage is cleared when the browser tab is closed (unlike localStorage which persists)

**3. "CORS errors"**
- ‚úÖ Check: `ALLOWED_ORIGIN` matches frontend domain
- ‚úÖ Check: API Gateway CORS configured
- ‚úÖ Check: OPTIONS preflight handler configured

**4. "Rate limiting errors"**
- ‚úÖ Check: API Gateway throttling settings
- ‚úÖ Check: Concurrent request count
- ‚úÖ Check: Bedrock quota limits

---

## References

- [AWS Bedrock Knowledge Bases](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html)
- [AWS Lambda Best Practices](https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html)
- [Boto3 Error Handling](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/error-handling.html)
- [sessionStorage MDN Docs](https://developer.mozilla.org/en-US/docs/Web/API/Window/sessionStorage)

---

## Quick Start

### 1. Deploy Lambda
```bash
# Package and deploy
zip function.zip lambda_function.py
aws lambda update-function-code \
  --function-name RetrieveAndGenerate \
  --zip-file fileb://function.zip
```

### 2. Configure Environment
```bash
aws lambda update-function-configuration \
  --function-name RetrieveAndGenerate \
  --environment "Variables={
    KNOWLEDGE_BASE_ID=your-kb-id,
    MODEL_ARN=cohere.command-r-v1:0,
    ALLOWED_ORIGIN=https://duoc.cl,
    TEMPERATURE=0.2,
    MAX_TOKENS=1024
  }"
```

### 3. Update Frontend
```javascript
// Add ChatHistory class and integrate with chatbot
// See implementation guide above
```

### 4. Test
```bash
# Test single query
curl -X POST $API_ENDPOINT -d '{"query":"What is Duoc UC?"}'

# Test with context
curl -X POST $API_ENDPOINT -d '{
  "query":"And how much?",
  "history":[
    {"role":"user","content":"What are fees?"},
    {"role":"assistant","content":"Fees are..."}
  ]
}'
```

---

**Last Updated:** November 2024  
**Version:** 2.0 (With Conversational Context)  
**Maintainer:** Duoc UC DevOps Team